{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tasN9HtsBrKq",
        "outputId": "1137d77a-f9b1-4112-a76a-b694f51c392d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17067, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 17067 (delta 24), reused 27 (delta 12), pack-reused 17022 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17067/17067), 15.68 MiB | 17.88 MiB/s, done.\n",
            "Resolving deltas: 100% (11714/11714), done.\n",
            "/content/yolov5\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.4/898.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q roboflow\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "%pip install -q roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qxl7edCBwcC",
        "outputId": "7ae83e67-a6d8-413e-ff72-b081f2b0d914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "enR0axfgB1qK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10df026c-0f3f-4514-c6cc-78424eb1dd59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SET UP COMPLETE. USING TORCH 2.5.1+cu121 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "from getpass import getpass\n",
        "from roboflow import Roboflow\n",
        "import torch\n",
        "import yaml\n",
        "from IPython.display import Image,display,clear_output\n",
        "print(f\"SET UP COMPLETE. USING TORCH {torch.__version__} ({torch.cuda.get_device_properties(0).name})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "LLyJX1bwB4q5",
        "outputId": "85393fda-376b-4654-d999-d6174e6747cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'train': '/content/drive/MyDrive/lane/train/images',\n",
              " 'val': '/content/drive/MyDrive/lane/valid/images',\n",
              " 'test': '/content/drive/MyDrive/lane/test/images',\n",
              " 'nc': 1,\n",
              " 'names': ['lane'],\n",
              " 'roboflow': {'workspace': 'lanes-qp7qp',\n",
              "  'project': 'culanes-m0cxq',\n",
              "  'version': 1,\n",
              "  'license': 'CC BY 4.0',\n",
              "  'url': 'https://universe.roboflow.com/lanes-qp7qp/culanes-m0cxq/dataset/1'}}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/lane'\n",
        "data_yaml='/content/drive/MyDrive/lane/data.yaml'\n",
        "assert(os.path.exists(data_dir)) and (os.path.exists(data_yaml))\n",
        "\n",
        "with open(data_yaml) as f:\n",
        "  film=yaml.load(f,Loader=yaml.FullLoader)\n",
        "  display(film)\n",
        "\n",
        "film['train' ] = os.path.join(data_dir,'/content/drive/MyDrive/lane/train/images')\n",
        "film['val']= os.path.join(data_dir,'/content/drive/MyDrive/lane/test/images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM72euJkB6iZ",
        "outputId": "40b14678-1d1b-48ed-e924-c47cd4dd9219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/segment/train.py\", line 30, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2130, in <module>\n",
            "    from torch import quantization as quantization  # usort: skip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/quantization/__init__.py\", line 2, in <module>\n",
            "    from .fake_quantize import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/quantization/fake_quantize.py\", line 10, in <module>\n",
            "    from torch.ao.quantization.fake_quantize import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/__init__.py\", line 8, in <module>\n",
            "    from .fake_quantize import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/fake_quantize.py\", line 10, in <module>\n",
            "    from torch.ao.quantization.observer import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py\", line 17, in <module>\n",
            "    from torch.ao.quantization.utils import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/utils.py\", line 13, in <module>\n",
            "    from torch.fx import Node\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/__init__.py\", line 83, in <module>\n",
            "    from .graph_module import GraphModule\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 20, in <module>\n",
            "    from .graph import _custom_builtins, _is_from_torch, _PyTreeCodeGen, Graph, PythonCode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph.py\", line 3, in <module>\n",
            "    from .node import Node, Argument, Target, map_arg, _type_repr, _get_qualified_name\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/fx/node.py\", line 49, in <module>\n",
            "    _ops.aten._assert_async.msg,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1223, in __getattr__\n",
            "    op, overload_names = _get_packet(qualified_op_name, module_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 1248, in _get_packet\n",
            "    op, overload_names = torch._C._jit_get_operation(qualname)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python segment/train.py --img 640 --batch 32 --epochs 40 --data {data_yaml} --weights yolov5s-seg.pt --cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "uSakkYEhB7kB",
        "outputId": "0b6e504b-ede5-4735-ef20-3118219e0c39"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/yolov5/runs/train-seg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b3fe8500969a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/yolov5/runs/train-seg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_folders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'triining exp 폴더 : {train_folders}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov5/runs/train-seg'"
          ]
        }
      ],
      "source": [
        "# train_path = '/content/yolov5/runs/train-seg'\n",
        "# train_folders=[folder for folder in os.listdir(train_path) if os.path.isdir(os.path.join(train_path,folder))]\n",
        "# print(f'triining exp 폴더 : {train_folders}')\n",
        "\n",
        "# test_data_dir=film['val']\n",
        "# training_folder='exp'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sISWkQlAB9Kd",
        "outputId": "6e34d9c7-ec68-41d2-c008-f47bc59b0830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[34m\u001b[1msegment/val: \u001b[0mdata=/content/drive/MyDrive/lane/data.yaml, weights=['runs/train-seg/{training_folder}/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val-seg, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v7.0-378-g2f74455a Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/segment/val.py\", line 522, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/segment/val.py\", line 493, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/segment/val.py\", line 211, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 489, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 98, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/patches.py\", line 86, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1319, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 659, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 640, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/train-seg/{training_folder}/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!python segment/val.py --weights runs/train-seg/{training_folder}/weights/best.pt --data '/content/drive/MyDrive/lane/data.yaml' --img 640\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NBLbXUdMCAnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3695b3c1-a50f-43f9-9c7a-8e363178e524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved: /content/drive/MyDrive/train/train/Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# # Split path 설정\n",
        "# if os.path.exists(os.path.join('/content/drive/MyDrive/lane', \"test\")):\n",
        "#     split_path = os.path.join('/content/drive/MyDrive/lane', \"test\", \"images\")\n",
        "# else:\n",
        "#     split_path = os.path.join('/content/drive/MyDrive/lane', \"valid\", \"images\")\n",
        "\n",
        "# # 예시 이미지 선택\n",
        "# example_image_name = os.listdir(split_path)[0]\n",
        "# example_image_path = os.path.join(split_path, example_image_name)\n",
        "\n",
        "# 선택한 이미지 경로\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# 선택한 이미지 경로\n",
        "image_to_test = \"/content/drive/MyDrive/lane/test_set/images/snow2.PNG\"\n",
        "\n",
        "# 이미지 전처리: 크기 조정 및 형식 변환\n",
        "def preprocess_image(input_path, output_path, size=(640, 640)):\n",
        "    with Image.open(input_path) as img:\n",
        "        img = img.resize(size, Image.LANCZOS)  # 이미지 크기 조정\n",
        "        # RGBA 모드일 경우 RGB로 변환\n",
        "        if img.mode == 'RGBA':\n",
        "            img = img.convert('RGB')  # RGBA를 RGB로 변환\n",
        "        img.save(output_path, format='JPEG')  # jpg 형식으로 저장\n",
        "\n",
        "# 전처리된 이미지 저장 경로\n",
        "processed_image_path = \"/content/drive/MyDrive/train/train/Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.jpg\"\n",
        "\n",
        "# 전처리 실행\n",
        "preprocess_image(image_to_test, processed_image_path)\n",
        "print(f\"Processed and saved: {processed_image_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sktsT3TkCEij",
        "outputId": "5b482074-4dd1-406d-dda8-e45ef2ab7234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[34m\u001b[1msegment/predict: \u001b[0mweights=['/content/drive/MyDrive/lane/best1.pt'], source=/content/drive/MyDrive/lane/test_set/images/-2024-10-19-120351_png.rf.77a208f0bbad0657915a8c47cfc94ea1.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/predict-seg, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1, retina_masks=False\n",
            "YOLOv5 🚀 v7.0-388-g882c35fc Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 165 layers, 7398422 parameters, 0 gradients, 25.7 GFLOPs\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/drive/MyDrive/lane/test_set/images/-2024-10-19-120351_png.rf.77a208f0bbad0657915a8c47cfc94ea1.jpg: 640x640 8 lanes, 14.7ms\n",
            "Speed: 0.7ms pre-process, 14.7ms inference, 746.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/predict-seg/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python segment/predict.py --img 640 --weights /content/drive/MyDrive/lane/best1.pt --source /content/drive/MyDrive/lane/test_set/images/-2024-10-19-120351_png.rf.77a208f0bbad0657915a8c47cfc94ea1.jpg --conf 0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YBcGc8tlekVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSrTP97ND355",
        "outputId": "a8a2ea7c-070d-443d-9505-762086258b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1msegment/predict: \u001b[0mweights=['/content/drive/MyDrive/lane/best1.pt'], source=/content/drive/MyDrive/lane/test_set/images/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/predict-seg, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1, retina_masks=False\n",
            "YOLOv5 🚀 v7.0-388-g882c35fc Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 165 layers, 7398422 parameters, 0 gradients, 25.7 GFLOPs\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "image 1/1 /content/drive/MyDrive/lane/test_set/images/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.jpg: 640x640 2 lanes, 14.7ms\n",
            "Speed: 0.6ms pre-process, 14.7ms inference, 642.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/predict-seg/exp5\u001b[0m\n",
            "1 labels saved to runs/predict-seg/exp5/labels\n"
          ]
        }
      ],
      "source": [
        "!python segment/predict.py --weights /content/drive/MyDrive/lane/best1.pt --source /content/drive/MyDrive/lane/test_set/images/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.jpg --img 640 --conf 0.1 --save-txt --save-conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyviJ6lhHdlx",
        "outputId": "6fdf959e-ea5f-41bb-f777-a56522aa22bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '0.3583333328125', '0.844380403125', '0.355', '0.844380403125', '0.20166666718749998', '0.99711815625', '0.2366666671875', '0.9913544671875', '0.3566666671875', '0.8645533140625', '0.3583333328125', '0.844380403125']\n",
            "[[229, 540], [227, 540], [129, 638], [151, 634], [228, 553], [229, 540]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 이미지 크기 정의\n",
        "width = 640  # 원본 이미지의 너비\n",
        "height = 640 # 원본 이미지의 높이\n",
        "\n",
        "# 원본 이미지 불러오기\n",
        "img = cv2.imread('/content/drive/MyDrive/lane/test_set/images/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.jpg')  # 원본 이미지 경로\n",
        "mask = np.zeros(img.shape[:2], np.uint8)  # 마스크 초기화\n",
        "\n",
        "# 레이블 파일 읽기\n",
        "with open('/content/drive/MyDrive/lane/test_set/labels/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip().split(\" \")\n",
        "\n",
        "        # 좌표 쌍 생성\n",
        "        pts_part = []\n",
        "        for i in range(1, len(line), 2):\n",
        "            # 인덱스 범위 체크\n",
        "            if i + 1 < len(line):  # 다음 인덱스가 범위 내에 있는지 확인\n",
        "                pts_part.append([int(float(line[i]) * width), int(float(line[i + 1]) * height)])\n",
        "            # else:\n",
        "            #     print(f\"Skipping incomplete coordinates: {line}\")\n",
        "            #     break  # 잘못된 좌표 쌍을 만나면 이 줄을 건너뜁니다.\n",
        "        # pts_part가 비어있지 않은 경우에만 윤곽선 그리기\n",
        "        if pts_part:\n",
        "            # 윤곽선 그리기\n",
        "            cv2.fillPoly(mask, [np.array(pts_part)], color=(255))\n",
        "print(line)\n",
        "print(pts_part)\n",
        "# 마스크 적용\n",
        "dst = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "# 결과 저장\n",
        "output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'output_image.jpg')  # 원하는 출력 경로\n",
        "cv2.imwrite(output_path, dst)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 이미지 크기 정의\n",
        "width = 640  # 원본 이미지의 너비\n",
        "height = 640 # 원본 이미지의 높이\n",
        "\n",
        "# 원본 이미지 불러오기\n",
        "img = cv2.imread('/content/drive/MyDrive/lane/test_set/images/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.jpg')  # 원본 이미지 경로\n",
        "mask = np.zeros(img.shape[:2], np.uint8)  # 마스크 초기화\n",
        "\n",
        "# 레이블 파일 읽기\n",
        "with open('/content/yolov5/runs/predict-seg/exp5/labels/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip().split(\" \")\n",
        "\n",
        "        # 좌표 쌍 생성\n",
        "        pts_part = []\n",
        "        for i in range(1, len(line), 2):\n",
        "            # 인덱스 범위 체크\n",
        "            if i + 1 < len(line):  # 다음 인덱스가 범위 내에 있는지 확인\n",
        "                pts_part.append([int(float(line[i]) * width), int(float(line[i + 1]) * height)])\n",
        "            # else:\n",
        "            #     print(f\"Skipping incomplete coordinates: {line}\")\n",
        "            #     break  # 잘못된 좌표 쌍을 만나면 이 줄을 건너뜁니다.\n",
        "        # pts_part가 비어있지 않은 경우에만 윤곽선 그리기\n",
        "        if pts_part:\n",
        "            # 윤곽선 그리기\n",
        "            cv2.fillPoly(mask, [np.array(pts_part)], color=(255))\n",
        "print(line)\n",
        "print(pts_part)\n",
        "# 마스크 적용\n",
        "dst = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "# 결과 저장\n",
        "output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'answer.jpg')  # 원하는 출력 경로\n",
        "# output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'output_image.jpg')  # 원하는 출력 경로\n",
        "\n",
        "cv2.imwrite(output_path, dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKbsUzCakHCT",
        "outputId": "f79dfe1d-cdd4-46ae-db51-71e40a3ed8df"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '0.371875', '0.83125', '0.370313', '0.832812', '0.365625', '0.832812', '0.35625', '0.842188', '0.35625', '0.84375', '0.35', '0.85', '0.35', '0.851562', '0.326562', '0.875', '0.325', '0.875', '0.325', '0.876562', '0.321875', '0.879687', '0.320312', '0.879687', '0.3125', '0.8875', '0.310937', '0.8875', '0.303125', '0.895312', '0.301562', '0.895312', '0.3', '0.896875', '0.3', '0.898438', '0.298438', '0.9', '0.296875', '0.9', '0.253125', '0.94375', '0.251563', '0.94375', '0.25', '0.945312', '0.25', '0.946875', '0.246875', '0.95', '0.245312', '0.95', '0.24375', '0.951563', '0.24375', '0.953125', '0.2375', '0.959375', '0.2375', '0.960938', '0.234375', '0.964063', '0.232812', '0.964063', '0.232812', '0.965625', '0.207813', '0.990625', '0.207813', '0.992188', '0.20625', '0.99375', '0.20625', '0.998438', '0.229687', '0.998438', '0.229687', '0.996875', '0.235938', '0.990625', '0.235938', '0.989062', '0.239063', '0.985937', '0.240625', '0.985937', '0.242188', '0.984375', '0.242188', '0.982813', '0.279687', '0.945312', '0.279687', '0.94375', '0.285937', '0.9375', '0.285937', '0.935938', '0.30625', '0.915625', '0.30625', '0.914062', '0.307813', '0.9125', '0.309375', '0.9125', '0.310937', '0.910937', '0.310937', '0.909375', '0.329688', '0.890625', '0.329688', '0.889063', '0.332812', '0.885938', '0.334375', '0.885938', '0.335938', '0.884375', '0.335938', '0.882812', '0.339063', '0.879687', '0.340625', '0.879687', '0.342187', '0.878125', '0.342187', '0.876562', '0.345313', '0.873438', '0.346875', '0.873438', '0.348437', '0.871875', '0.348437', '0.870313', '0.351562', '0.867188', '0.353125', '0.867188', '0.354688', '0.865625', '0.354688', '0.864062', '0.357812', '0.860937', '0.359375', '0.860937', '0.365625', '0.854688', '0.367188', '0.854688', '0.373437', '0.848437', '0.373437', '0.846875', '0.384375', '0.835938', '0.384375', '0.832812', '0.382812', '0.83125', '0.92088']\n",
            "[[238, 532], [237, 532], [234, 532], [228, 539], [228, 540], [224, 544], [224, 544], [208, 560], [208, 560], [208, 560], [206, 562], [204, 562], [200, 568], [198, 568], [194, 572], [192, 572], [192, 574], [192, 575], [191, 576], [190, 576], [162, 604], [161, 604], [160, 604], [160, 606], [158, 608], [156, 608], [156, 609], [156, 610], [152, 614], [152, 615], [150, 617], [148, 617], [148, 618], [133, 634], [133, 635], [132, 636], [132, 639], [146, 639], [146, 638], [151, 634], [151, 632], [153, 630], [154, 630], [155, 630], [155, 629], [178, 604], [178, 604], [182, 600], [182, 599], [196, 586], [196, 584], [197, 584], [198, 584], [198, 582], [198, 582], [211, 570], [211, 569], [212, 567], [214, 567], [215, 566], [215, 564], [217, 562], [218, 562], [218, 562], [218, 560], [221, 559], [222, 559], [222, 558], [222, 557], [224, 555], [226, 555], [227, 554], [227, 552], [228, 550], [230, 550], [234, 547], [235, 547], [238, 542], [238, 542], [246, 535], [246, 532], [244, 532]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "-5XsBniuHeGE",
        "outputId": "2a68d5c1-2d24-474d-9ddc-38c2accdb4e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced mask image saved at: /content/yolov5/runs/predict-seg/exp/output_image.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 마스크 이미지 경로\n",
        "mask_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'answer.jpg')\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # 마스크를 그레이스케일로 읽기\n",
        "\n",
        "# 차선 픽셀만 남기기\n",
        "lane_pixels = np.where(mask >= 10)  # 차선 픽셀\n",
        "\n",
        "# 새로운 마스크 이미지를 생성 (배경을 모두 검정색으로 설정)\n",
        "new_mask = np.zeros_like(mask)  # 기존 마스크와 동일한 크기의 검정색 이미지 생성\n",
        "new_mask[lane_pixels] = 255  # 차선이 있는 위치에 흰색(255) 설정\n",
        "\n",
        "# 새로운 마스크 이미지 시각화\n",
        "plt.imshow(new_mask, cmap='gray')\n",
        "plt.title('Lane Only Mask')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 새로운 마스크 이미지 저장 경로\n",
        "final_output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'output_image.jpg')\n",
        "\n",
        "# 새로운 마스크 이미지 저장\n",
        "cv2.imwrite(final_output_path, new_mask)\n",
        "print(f\"Enhanced mask image saved at: {final_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOid4PzW_rl4",
        "outputId": "c4b39510-5a30-429d-cfe4-3d1d314af4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BDA 적용 후 최종 차선 마스크 저장 경로: /content/yolov5/runs/predict-seg/exp/enhanced1_output_image.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 마스크 이미지 경로\n",
        "mask_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'output_image.jpg')\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # 마스크를 그레이스케일로 읽기\n",
        "\n",
        "# 차선과 배경의 픽셀 값\n",
        "lane_pixels = np.where(mask > 10)  # 차선 픽셀\n",
        "background_pixels = np.where(mask < 0)  # 배경 픽셀\n",
        "\n",
        "# 이미지 전처리 함수 (모자 형태의 커널 적용)\n",
        "def preprocess_image(image, a):\n",
        "    # 그레이스케일로 변환\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 모자 형태의 커널 생성: 가로 비율 a/2a/a\n",
        "    kernel_width = 4 * a  # 총 너비는 4a\n",
        "    kernel_height = 3  # 3개의 행으로 구성\n",
        "\n",
        "    # 커널 초기화\n",
        "    kernel = np.zeros((kernel_height, kernel_width), dtype=np.float32)\n",
        "\n",
        "    kernel[0, a:3*a] = 1  # 첫 번째 행의 중간 2a 부분을 1로 설정\n",
        "    kernel[1, a:3*a] = 1  # 두 번째 행의 중간 2a 부분을 1로 설정\n",
        "\n",
        "    # -1 영역 정의 (세 번째 행)\n",
        "    kernel[2, :] = -1     # 세 번째 행 전체를 -1로 채움\n",
        "\n",
        "    # 커널을 사용하여 컨볼루션 적용\n",
        "    filtered_image = cv2.filter2D(gray, -1, kernel)\n",
        "\n",
        "    # 임계값 처리를 통해 윤곽선 강조\n",
        "    _, contour_image = cv2.threshold(filtered_image, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return contour_image\n",
        "\n",
        "# 특징 추출 함수 정의\n",
        "def extract_features(image, pixels, window_size=5):\n",
        "    features = []\n",
        "    half_window = window_size // 2\n",
        "\n",
        "    for y, x in zip(pixels[0], pixels[1]):\n",
        "        # 주변 영역 추출\n",
        "        x_start = max(0, x - half_window)\n",
        "        x_end = min(image.shape[1], x + half_window + 1)\n",
        "        y_start = max(0, y - half_window)\n",
        "        y_end = min(image.shape[0], y + half_window + 1)\n",
        "\n",
        "        # 주변 영역의 평균값을 특징으로 사용\n",
        "        window = image[y_start:y_end, x_start:x_end]\n",
        "        mean_value = np.mean(window)\n",
        "        features.append(mean_value)\n",
        "\n",
        "    return np.array(features).reshape(-1, 1)  # 2차원 배열로 반환\n",
        "\n",
        "# 원본 이미지 불러오기\n",
        "img_path = '/content/drive/MyDrive/lane/test_set/images/14498_22756_5732_png.rf.beae3e12dea29caf3bcd21c8834613c4.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "if img is None:\n",
        "    raise ValueError(\"원본 이미지를 불러오는 데 실패했습니다.\")\n",
        "\n",
        "# 이미지 전처리\n",
        "a = 6 # a의 값 설정\n",
        "contour_image = preprocess_image(img, a)\n",
        "\n",
        "# 차선 픽셀의 주변 픽셀 값 추출\n",
        "lane_features = extract_features(contour_image, lane_pixels)\n",
        "\n",
        "# 레이블 생성 (차선: 1)\n",
        "labels = np.array([1] * lane_features.shape[0])  # 배경에 대한 레이블은 필요 없음\n",
        "all_features = lane_features  # 배경은 포함하지 않음\n",
        "\n",
        "# BDA를 통한 판별 함수 학습\n",
        "def biased_discriminant_analysis(X, y, alpha=1.0):\n",
        "    # 각 클래스의 평균 및 공분산 계산\n",
        "    mean_lanes = np.mean(X[y == 1], axis=0)\n",
        "\n",
        "    # 공분산 행렬의 정칙화\n",
        "    cov_lanes = np.cov(X[y == 1], rowvar=False) + np.eye(X.shape[1]) * alpha\n",
        "\n",
        "    # 공분산 행렬의 역행렬\n",
        "    cov_inv = np.linalg.pinv(cov_lanes)\n",
        "\n",
        "    # BDA 판별 함수의 계수\n",
        "    coeff = cov_inv @ (mean_lanes)\n",
        "\n",
        "    return coeff, mean_lanes\n",
        "\n",
        "# BDA 적용\n",
        "coeff, mean_lanes = biased_discriminant_analysis(all_features, labels)\n",
        "\n",
        "# 예측\n",
        "projections = all_features @ coeff\n",
        "threshold = np.mean(projections)  # 평균 임계값 설정\n",
        "predictions = (projections >= threshold).astype(int)\n",
        "\n",
        "# 새 마스크 생성 (차선 픽셀 강화)\n",
        "enhanced_mask = np.zeros_like(mask)\n",
        "for i, pred in enumerate(predictions):\n",
        "    if pred == 1:\n",
        "        y, x = lane_pixels[0][i], lane_pixels[1][i]\n",
        "        enhanced_mask[y, x] = 255  # 차선으로 예측된 픽셀은 흰색으로 설정\n",
        "\n",
        "# 잡음 제거를 위한 모폴로지 연산\n",
        "kernel = np.ones((4, 4), np.uint8)  # 3x3 커널\n",
        "enhanced_mask = cv2.morphologyEx(enhanced_mask, cv2.MORPH_CLOSE, kernel)  # 닫힘 연산\n",
        "\n",
        "# 최종 차선 마스크 저장\n",
        "final_output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'enhanced1_output_image.jpg')\n",
        "cv2.imwrite(final_output_path, enhanced_mask)\n",
        "\n",
        "# 디버깅 출력 (선택 사항)\n",
        "print(\"BDA 적용 후 최종 차선 마스크 저장 경로:\", final_output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import img_as_float\n",
        "from skimage.segmentation import active_contour\n",
        "\n",
        "# B-Snake 적용 함수 정의\n",
        "def apply_bsnake(image, mask):\n",
        "    # 이미지 전처리\n",
        "    img_float = img_as_float(image)\n",
        "\n",
        "    # 마스크에서 초기 곡선 생성 (B-Snake가 따라갈 초기 곡선)\n",
        "    # 마스크의 1 값 위치 찾기\n",
        "    y, x = np.where(mask > 0)  # 마스크에서 포인트 추출\n",
        "\n",
        "    # 초기 곡선 포인트 배열 생성\n",
        "    init = np.array([x, y]).T\n",
        "\n",
        "    # B-Snake 적용\n",
        "    snake = active_contour(img_float, init, alpha=0.015, beta=10, gamma=0.001,\n",
        "                            boundary_condition='periodic')\n",
        "\n",
        "    return snake\n",
        "\n",
        "# 원본 이미지 불러오기\n",
        "img_path = '/content/drive/MyDrive/train/train/Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "if img is None:\n",
        "    raise ValueError(\"원본 이미지를 불러오는 데 실패했습니다.\")\n",
        "\n",
        "# enhanced_mask를 정의해야 합니다. 여기서는 이미 정의된 것으로 가정합니다.\n",
        "# enhanced_mask = ...\n",
        "\n",
        "# B-Snake 적용\n",
        "bsnake_result = apply_bsnake(img, enhanced_mask)\n",
        "\n",
        "# 결과 시각화\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.plot(bsnake_result[:, 0], bsnake_result[:, 1], '-r', lw=3)  # B-Snake 곡선\n",
        "plt.title('B-Snake 적용 결과')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 최종 B-Snake 마스크 생성\n",
        "final_bsnake_mask = np.zeros_like(enhanced_mask)\n",
        "for point in bsnake_result.astype(int):\n",
        "    cv2.circle(final_bsnake_mask, tuple(point), 1, (255), -1)\n",
        "\n",
        "# 최종 B-Snake 마스크 저장\n",
        "final_bsnake_output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'bsnake_output_image.jpg')\n",
        "cv2.imwrite(final_bsnake_output_path, final_bsnake_mask)\n",
        "\n",
        "# 디버깅 출력 (선택 사항)\n",
        "print(\"B-Snake 최종 마스크 저장 경로:\", final_bsnake_output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Q42JYSQM6GmC",
        "outputId": "24dd488f-f8fb-4cde-f9a6-fb1a70b92afe"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "원본 이미지를 불러오는 데 실패했습니다.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-38a13909c726>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"원본 이미지를 불러오는 데 실패했습니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# 이미지 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 원본 이미지를 불러오는 데 실패했습니다."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1JgBpcrkHso9",
        "outputId": "20755a94-6612-4116-a792-ca20d20a6631"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "BDA 마스크 이미지를 불러오는 데 실패했습니다.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2e759fa839d1>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbda_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BDA 마스크 이미지를 불러오는 데 실패했습니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 왼쪽 라인과 오른쪽 라인 픽셀 찾기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: BDA 마스크 이미지를 불러오는 데 실패했습니다."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# BDA 마스크 이미지 경로\n",
        "bda_mask_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'enhanced_output_image.jpg')\n",
        "bda_mask = cv2.imread(bda_mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "if bda_mask is None:\n",
        "    raise ValueError(\"BDA 마스크 이미지를 불러오는 데 실패했습니다.\")\n",
        "\n",
        "# 왼쪽 라인과 오른쪽 라인 픽셀 찾기\n",
        "left_lane_pixels = np.where(bda_mask[:, :bda_mask.shape[1] // 2] == 255)\n",
        "right_lane_pixels = np.where(bda_mask[:, bda_mask.shape[1] // 2:] == 255)\n",
        "\n",
        "# 예측된 차선 포인트 (y, x 좌표)\n",
        "left_predicted_points = np.array([(y, x) for y, x in zip(left_lane_pixels[0], left_lane_pixels[1])])\n",
        "right_predicted_points = np.array([(y, x + bda_mask.shape[1] // 2) for y, x in zip(right_lane_pixels[0], right_lane_pixels[1])])\n",
        "\n",
        "# 차선 포인트가 충분히 있는지 확인\n",
        "if len(left_predicted_points) < 2:\n",
        "    raise ValueError(\"왼쪽 차선 포인트가 충분하지 않습니다.\")\n",
        "if len(right_predicted_points) < 2:\n",
        "    raise ValueError(\"오른쪽 차선 포인트가 충분하지 않습니다.\")\n",
        "\n",
        "# 중간 포인트 계산\n",
        "def get_middle_points(points):\n",
        "    # y 값에 따라 정렬\n",
        "    sorted_points = points[np.argsort(points[:, 0])]\n",
        "    middle_points = []\n",
        "\n",
        "    # 중간 포인트 계산\n",
        "    for i in range(len(sorted_points) - 1):\n",
        "        y_avg = (sorted_points[i][0] + sorted_points[i + 1][0]) // 2\n",
        "        x_avg = (sorted_points[i][1] + sorted_points[i + 1][1]) // 2\n",
        "        middle_points.append((y_avg, x_avg))\n",
        "\n",
        "    return np.array(middle_points)\n",
        "\n",
        "# 중간 포인트 생성\n",
        "left_middle_points = get_middle_points(left_predicted_points)\n",
        "right_middle_points = get_middle_points(right_predicted_points)\n",
        "\n",
        "# 각 차선 그리기 함수\n",
        "def draw_lane(mask, points, color=255):\n",
        "    for i in range(len(points) - 1):\n",
        "        pt1 = (points[i][1], points[i][0])  # (x, y)\n",
        "        pt2 = (points[i + 1][1], points[i + 1][0])\n",
        "        cv2.line(mask, pt1, pt2, color, thickness=5)\n",
        "\n",
        "# 최종 차선 마스크 초기화\n",
        "final_lane_mask = np.zeros_like(bda_mask)\n",
        "\n",
        "# 각 차선을 그리기\n",
        "draw_lane(final_lane_mask, left_middle_points, color=255)  # 왼쪽 차선\n",
        "draw_lane(final_lane_mask, right_middle_points, color=255)  # 오른쪽 차선\n",
        "\n",
        "# 최종 차선 마스크 저장\n",
        "final_output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'lane_output_image.jpg')\n",
        "cv2.imwrite(final_output_path, final_lane_mask)\n",
        "\n",
        "# 디버깅 출력\n",
        "print(\"차선을 연결한 최종 마스크 저장 경로:\", final_output_path)\n",
        "\n",
        "# 원본 이미지 불러오기 (옵션)\n",
        "original_image_path = '/content/drive/MyDrive/train/train/Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.jpg'\n",
        "original_image = cv2.imread(original_image_path)\n",
        "\n",
        "if original_image is None:\n",
        "    raise ValueError(\"원본 이미지를 불러오는 데 실패했습니다.\")\n",
        "\n",
        "# 차선 마스크를 3채널로 변환하여 원본 이미지와 합성 가능하게 만들기\n",
        "final_lane_mask_color = cv2.cvtColor(final_lane_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# 원본 이미지에 차선을 덧씌우기\n",
        "result_image = cv2.addWeighted(original_image, 0.8, final_lane_mask_color, 0.2, 0)\n",
        "\n",
        "# 결과 이미지 저장\n",
        "result_output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'result_image_with_lane.jpg')\n",
        "cv2.imwrite(result_output_path, result_image)\n",
        "\n",
        "print(\"원본 이미지에 차선을 덧씌운 결과 저장 경로:\", result_output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw4Jr8EECmfj",
        "outputId": "6e401b86-8bba-4d2d-81c8-64dde5635622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catmull-Rom spline 적용 후 최종 보정된 차선 마스크 저장 경로: /content/yolov5/runs/predict-seg/exp/enhanced_spline_output_image.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "\n",
        "# 마스크 이미지 경로\n",
        "mask_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'enhanced_output_image.jpg')\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# 차선 픽셀 추출\n",
        "lane_pixels = np.where(mask > 0)\n",
        "y_coords = lane_pixels[0]\n",
        "x_coords = lane_pixels[1]\n",
        "\n",
        "# Catmull-Rom spline 보간 함수 정의\n",
        "def catmull_rom_spline(x, y, num_points=100):\n",
        "    # 입력된 제어점을 Catmull-Rom spline으로 보간\n",
        "    sorted_indices = np.argsort(x)\n",
        "    x = np.array(x)[sorted_indices]\n",
        "    y = np.array(y)[sorted_indices]\n",
        "\n",
        "    # 중복된 x 값을 제거하고 고유한 x 값만 사용\n",
        "    unique_x, unique_indices = np.unique(x, return_index=True)\n",
        "    y = y[unique_indices]\n",
        "\n",
        "    # CubicSpline을 사용하여 Catmull-Rom spline 보간 수행\n",
        "    spline = CubicSpline(unique_x, y)\n",
        "\n",
        "    # spline을 따라 부드러운 곡선을 생성\n",
        "    x_interp = np.linspace(unique_x.min(), unique_x.max(), num_points)\n",
        "    y_interp = spline(x_interp)\n",
        "\n",
        "    return x_interp, y_interp\n",
        "\n",
        "# Catmull-Rom spline 적용하여 보정된 차선 곡선 얻기\n",
        "x_spline, y_spline = catmull_rom_spline(x_coords, y_coords)\n",
        "\n",
        "# 새 마스크에 spline 차선 그리기\n",
        "enhanced_spline_mask = np.zeros_like(mask)\n",
        "\n",
        "# 보간된 곡선을 마스크에 그리기\n",
        "for x, y in zip(x_spline, y_spline):\n",
        "    x = int(round(x))\n",
        "    y = int(round(y))\n",
        "    if 0 <= x < enhanced_spline_mask.shape[1] and 0 <= y < enhanced_spline_mask.shape[0]:\n",
        "        enhanced_spline_mask[y, x] = 255\n",
        "\n",
        "# 잡음 제거를 위한 모폴로지 연산\n",
        "kernel = np.ones((3, 3), np.uint8)  # 3x3 커널\n",
        "enhanced_spline_mask = cv2.morphologyEx(enhanced_spline_mask, cv2.MORPH_CLOSE, kernel)  # 닫힘 연산\n",
        "\n",
        "# 원본 이미지 불러오기\n",
        "original_image_path = os.path.join('/content/drive/MyDrive/train/train', 'Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.jpg')  # 원본 이미지 경로\n",
        "original_image = cv2.imread(original_image_path)\n",
        "\n",
        "# 마스크를 원본 이미지에 적용\n",
        "# 3채널로 변환하여 색상 정보를 유지\n",
        "enhanced_spline_mask_colored = cv2.cvtColor(enhanced_spline_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# 마스크 적용: 원본 이미지와 마스크의 비트 AND 연산\n",
        "result_image = cv2.addWeighted(original_image, 0.8, enhanced_spline_mask_colored, 0.2, 0)\n",
        "\n",
        "# 최종 보정된 차선 마스크 저장\n",
        "final_spline_output_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'enhanced_spline_output_image.jpg')\n",
        "cv2.imwrite(final_spline_output_path, result_image)\n",
        "\n",
        "# 디버깅 출력 (선택 사항)\n",
        "print(\"Catmull-Rom spline 적용 후 최종 보정된 차선 마스크 저장 경로:\", final_spline_output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLHakLBAB7HW",
        "outputId": "611a18f1-62f7-4da4-9504-f73fa8f6b096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Catmull-Rom spline 적용 후 최종 이미지 저장 경로: /content/yolov5/runs/predict-seg/exp/final_spline_image.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "\n",
        "# Catmull-Rom spline 보간 함수\n",
        "def catmull_rom_spline(x, y, num_points=100):\n",
        "    # 입력 좌표가 4개 미만인 경우 보간을 수행할 수 없으므로 그대로 반환\n",
        "    if len(x) < 4:\n",
        "        return x, y\n",
        "\n",
        "    # CubicSpline을 이용해 Catmull-Rom spline 생성\n",
        "    cs = CubicSpline(x, y)\n",
        "    x_new = np.linspace(min(x), max(x), num_points)\n",
        "    y_new = cs(x_new)\n",
        "    return x_new, y_new\n",
        "\n",
        "# 새 마스크에 spline 차선 그리기 함수\n",
        "def draw_spline_on_image(image, x_spline, y_spline, color=(0, 0, 255), thickness=2):\n",
        "    for i in range(1, len(x_spline)):\n",
        "        # 이전 점과 현재 점을 연결하여 선을 그림\n",
        "        start_point = (int(x_spline[i - 1]), int(y_spline[i - 1]))\n",
        "        end_point = (int(x_spline[i]), int(y_spline[i]))\n",
        "        cv2.line(image, start_point, end_point, color, thickness)\n",
        "    return image\n",
        "\n",
        "# 원본 이미지 불러오기\n",
        "img_path = '/content/drive/MyDrive/train/train/Town04_Clear_Noon_09_09_2020_14_57_22_frame_0.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "if img is None:\n",
        "    raise ValueError(\"원본 이미지를 불러오는 데 실패했습니다.\")\n",
        "\n",
        "# x_coords와 y_coords를 정렬하여 보간 함수에 전달\n",
        "unique_indices = np.unique(x_coords, return_index=True)[1]  # 중복 제거\n",
        "x_unique = x_coords[unique_indices]\n",
        "y_unique = y_coords[unique_indices]\n",
        "\n",
        "# x와 y를 함께 정렬\n",
        "sorted_indices = np.argsort(x_unique)\n",
        "x_sorted = x_unique[sorted_indices]\n",
        "y_sorted = y_unique[sorted_indices]\n",
        "\n",
        "# 보정된 차선 좌표로 Catmull-Rom spline 생성\n",
        "x_spline, y_spline = catmull_rom_spline(x_sorted, y_sorted)\n",
        "\n",
        "# 원본 이미지 위에 spline 차선을 그림\n",
        "result_image = draw_spline_on_image(img.copy(), x_spline, y_spline)\n",
        "\n",
        "# 최종 이미지 저장 경로 설정\n",
        "final_image_path = os.path.join('/content/yolov5/runs/predict-seg/exp', 'final_spline_image.jpg')\n",
        "\n",
        "# 결과 이미지 저장\n",
        "cv2.imwrite(final_image_path, result_image)\n",
        "\n",
        "# 디버깅 출력 (선택 사항)\n",
        "print(\"Catmull-Rom spline 적용 후 최종 이미지 저장 경로:\", final_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "j4Xh0Ly-CBQ6",
        "outputId": "9b616d8f-5f82-4934-d280-e6e2abc72ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- YOLO Model ---\n",
            "Precision: 0.8008\n",
            "FPR: 0.0010\n",
            "MAE: 0.2547\n",
            "\n",
            "--- Post-Processed Model ---\n",
            "Precision: 0.8253\n",
            "FPR: 0.0005\n",
            "MAE: 0.1214\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'mask_comparison_results.csv'.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 마스크 경로 설정 (수정 필요)\n",
        "ground_truth_mask_path = '/content/yolov5/runs/predict-seg/exp/answer_image.jpg'  # 정답 마스크 경로\n",
        "model1_mask_path = '/content/yolov5/runs/predict-seg/exp/output_image.jpg'         # YOLO 모델 마스크 경로\n",
        "model2_mask_path = '/content/yolov5/runs/predict-seg/exp/enhanced1_output_image.jpg'  # 후처리 모델 마스크 경로\n",
        "\n",
        "# 결과 저장용 리스트 초기화\n",
        "results = []\n",
        "\n",
        "def calculate_metrics(ground_truth, model_mask):\n",
        "    \"\"\"\n",
        "    Precision, FPR, MAE를 계산합니다.\n",
        "    \"\"\"\n",
        "    TP = np.sum(np.logical_and(ground_truth == 1, model_mask == 1))  # True Positives\n",
        "    FP = np.sum(np.logical_and(ground_truth == 0, model_mask == 1))  # False Positives\n",
        "    FN = np.sum(np.logical_and(ground_truth == 1, model_mask == 0))  # False Negatives\n",
        "    TN = np.sum(np.logical_and(ground_truth == 0, model_mask == 0))  # True Negatives\n",
        "\n",
        "    # Precision 계산\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "    # FPR 계산\n",
        "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
        "\n",
        "    # MAE 계산\n",
        "    mae = np.mean(np.abs(ground_truth - model_mask))\n",
        "\n",
        "    return precision, fpr, mae\n",
        "\n",
        "def compare_masks(ground_truth, model_mask, model_name):\n",
        "    \"\"\"\n",
        "    각 모델의 성능 지표를 계산하고 결과 리스트에 저장합니다.\n",
        "    \"\"\"\n",
        "    precision, fpr, mae = calculate_metrics(ground_truth, model_mask)\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'Precision': precision,\n",
        "        'FPR': fpr,\n",
        "        'MAE': mae\n",
        "    })\n",
        "\n",
        "    print(f'--- {model_name} ---')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'FPR: {fpr:.4f}')\n",
        "    print(f'MAE: {mae:.4f}\\n')\n",
        "\n",
        "def visualize_comparison(ground_truth, model1_mask, model2_mask):\n",
        "    \"\"\"\n",
        "    정답 마스크와 모델 마스크를 시각화합니다.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title('Ground Truth Mask')\n",
        "    plt.imshow(ground_truth, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title('YOLO Model')\n",
        "    plt.imshow(model1_mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title('Post-Processed Model')\n",
        "    plt.imshow(model2_mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # 정답 마스크 로드\n",
        "    ground_truth_mask = cv2.imread(ground_truth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if ground_truth_mask is None:\n",
        "        print(\"Error: Ground truth mask not found.\")\n",
        "        return\n",
        "    ground_truth_mask = (ground_truth_mask > 128).astype(np.uint8)  # 이진화\n",
        "\n",
        "    # YOLO 모델 마스크 로드\n",
        "    model1_mask = cv2.imread(model1_mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if model1_mask is None:\n",
        "        print(\"Error: Model 1 mask not found.\")\n",
        "        return\n",
        "    model1_mask = (model1_mask > 128).astype(np.uint8)  # 이진화\n",
        "\n",
        "    # 후처리 모델 마스크 로드\n",
        "    model2_mask = cv2.imread(model2_mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if model2_mask is None:\n",
        "        print(\"Error: Model 2 mask not found.\")\n",
        "        return\n",
        "    model2_mask = (model2_mask > 128).astype(np.uint8)  # 이진화\n",
        "\n",
        "    # 각 모델의 성능 비교\n",
        "    compare_masks(ground_truth_mask, model1_mask, \"YOLO Model\")\n",
        "    compare_masks(ground_truth_mask, model2_mask, \"Post-Processed Model\")\n",
        "\n",
        "    # 마스크 시각화\n",
        "    visualize_comparison(ground_truth_mask, model1_mask, model2_mask)\n",
        "\n",
        "    # 결과를 데이터프레임으로 변환 후 CSV 파일로 저장\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv('mask_comparison_results.csv', index=False)\n",
        "    print(\"Results saved to 'mask_comparison_results.csv'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "jFKvQFIokayE",
        "outputId": "5d6c1b83-58f1-4c6c-ca1d-7786caf41b36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-163793ed1820>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-163793ed1820>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mmodel2_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2_mask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmodel2_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel2_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 이진화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mground_truth_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel1_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel2_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
          ]
        }
      ],
      "source": [
        "--- YOLO Model ---\n",
        "Precision: 0.4449\n",
        "FPR: 0.0032\n",
        "MAE: 0.8096\n",
        "\n",
        "--- Post-Processed Model ---\n",
        "Precision: 0.6191\n",
        "FPR: 0.0010\n",
        "MAE: 0.2441\n",
        "\n",
        "--- YOLO Model ---\n",
        "Precision: 0.9268\n",
        "FPR: 0.0002\n",
        "MAE: 0.0475\n",
        "\n",
        "--- Post-Processed Model ---\n",
        "Precision: 0.9198\n",
        "FPR: 0.0001\n",
        "MAE: 0.0323"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}